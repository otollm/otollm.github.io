<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="A Deep Learning Approach Harnessing Large Language Models for Otoscopic Image Understanding.">
  <meta name="keywords" content="Deep Learning, Large Language Models, LLM, Otoscopy, Otoscopic">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>A Deep Learning Approach Harnessing Large Language Models for Otoscopic Image Understanding.</title>

  <link href="https://fonts.loli.net/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://cdnjs.loli.net/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">A Deep Learning Approach Harnessing Large Language Models for Otoscopic Image Understanding</h1>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Demo Link. -->
                <span class="link-block">
                  <a href="https://bit.ly/otollm" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-play"></i>
                    </span>
                    <span>Demo</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/otollm/code" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Model Link. -->
                <span class="link-block">
                  <a href="https://github.com/otollm/models" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-box"></i>
                    </span>
                    <span>Model</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://github.com/otollm/datasets" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="demo-body">
        <h2 class="title has-text-centered">Online Demo</h2>
        <img src="./static/images/demo.jpg" alt="Image of the online demo "/>
        <h2 class="subtitle has-text-centered">
          This demo is publicly available at <a href="https://bit.ly/otollm">here</a>. Users can upload otoscopic images and receive immediate descriptions from OtoLLM.
        </h2>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="gpt4-body">
        <h2 class="title has-text-centered">Comparison with GPT-4</h2>
        <img src="./static/images/gpt4.jpg" alt="Image of the comparison with GPT-4"/>
        <h2 class="subtitle has-text-centered">
          These are the descriptions generated by both GPT-4 (left) and OtoLLM (right) for the same otoscopic image. While GPT-4 provides a vague and nonsensical description, OtoLLM offers a more concise and accurate description.
        </h2>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>Otoscopy plays a pivotal role in diagnosing ear diseases, yet interpreting otoscopic images remains challenging due to the intricate nature of the ear and variability across individuals. This study introduces OtoLLM, a multi-modal deep learning framework that leverages large language models (LLMs) for the automated interpretation of otoscopic images. Leveraging an expansive dataset comprising 27900 otoscopic images sourced from 12639 patients across three branches of a tertiary hospital, OtoLLM combines advanced visual processing with linguistic capabilities to generate precise descriptions of otoscopic images. The model is evaluated against conventional metrics such as BLEU and CIDEr, and a novel human evaluation metric Key Points Coverage, designed to assess clinical relevance. OtoLLM achieves superior performance in all metrics compared to other methods, indicating its effectiveness in providing clinically relevant interpretations.</p>
            <p>Designed for low computational overhead, OtoLLM can also be deployed locally, ensuring broad accessibility and addressing privacy concerns. Furthermore, OtoLLM's open-source nature and the provision of an online demo highlight its commitment to accessibility and practical utility in clinical practice. This study represents a significant advancement in the application of AI in otolaryngology, offering a scalable and effective solution for the automated interpretation of otoscopic images, with broader implications for healthcare delivery and diagnostic processes.</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/otollm/otollm.github.io">source code</a> of this website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>